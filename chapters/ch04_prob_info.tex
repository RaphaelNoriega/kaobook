\chapter{Probability, Statistics, and Information Theory}
\section{Random variables and distributions}
% TODO
\subsection{Sample spaces and events}
\subsection{Discrete and continuous random variables}
\subsection{Probability mass and density functions (PMF, PDF)}
\subsection{Cumulative distribution functions (CDF)}
\subsection{Joint, marginal, and conditional distributions}

\section{Expectation, variance, covariance}
% TODO
\subsection{Expected value of random variables}
\subsection{Variance and standard deviation}
\subsection{Covariance and correlation}
\subsection{Covariance matrices}
\subsection{Law of large numbers and central limit theorem}

\section{Gaussian and exponential families}
% TODO
\subsection{Gaussian (normal) distribution properties}
\subsection{Multivariate Gaussian distribution}
\subsection{Exponential family definition and structure}
\subsection{Bernoulli, Binomial, Poisson, and Exponential as exponential-family members}
\subsection{Maximum likelihood under exponential families}

\section{Entropy, KL divergence, mutual information}
% TODO
\subsection{Shannon entropy and information content}
\subsection{Cross-entropy and its link to loss functions}
\subsection{Kullback–Leibler divergence}
\subsection{Mutual information}
\subsection{Applications in machine learning (regularization, uncertainty, feature selection)}

