\chapter{Optimization in Machine Learning}

\section{Least Squares and Maximum Likelihood}
\subsection{Ordinary least squares formulation}
\subsection{Normal equations and closed-form solution}
\subsection{Maximum likelihood estimation (MLE)}
\subsection{Connection between least squares and Gaussian likelihood}
\subsection{Log-likelihood and optimization objectives}

\section{Convex vs. Non-Convex Optimization}
\subsection{Convex sets and convex functions}
\subsection{Properties of convex optimization problems}
\subsection{Challenges of non-convex landscapes}
\subsection{Local minima vs global minima}
\subsection{Saddle points and flat regions}

\section{Gradient Descent and Variants}
\subsection{Batch gradient descent}
\subsection{Stochastic gradient descent (SGD)}
\subsection{Mini-batch gradient descent}
\subsection{Learning rate scheduling}
\subsection{Momentum, RMSProp, and Adam optimizers}