\chapter{Core Algorithms of Classical ML}

\section{Linear and Logistic Regression}
\subsection{Linear regression model formulation}
\subsection{Least squares estimation}
\subsection{Regularization (Ridge and Lasso)}
\subsection{Logistic regression for classification}
\subsection{Decision boundaries and sigmoid function}
\subsection{Evaluation metrics (accuracy, ROC, AUC)}

\section{Support Vector Machines (SVMs) and Kernels}
\subsection{Maximum margin classifiers}
\subsection{Soft margin SVMs}
\subsection{Kernel trick and feature mapping}
\subsection{Common kernels (linear, polynomial, RBF)}
\subsection{Support vector regression (SVR)}
\subsection{Computational considerations}

\section{Decision Trees, Random Forests, and Boosting}
\subsection{Decision tree construction (ID3, CART)}
\subsection{Overfitting and pruning}
\subsection{Bagging and random forests}
\subsection{Boosting algorithms (AdaBoost, Gradient Boosting, XGBoost)}
\subsection{Feature importance and interpretability}