\chapter{Explainability and Interpretability}
\section{Saliency Maps and Grad-CAM}
\subsection{Saliency maps for visualizing input sensitivity}
\subsection{Gradient-based attribution methods}
\subsection{Grad-CAM (Gradient-weighted Class Activation Mapping)}
\subsection{Guided backpropagation and integrated gradients}
\subsection{Limitations and reliability concerns}

\section{SHAP and LIME}
\subsection{Model-agnostic interpretability approaches}
\subsection{Local Interpretable Model-agnostic Explanations (LIME)}
\subsection{SHAP values and Shapley game-theoretic foundation}
\subsection{Comparing SHAP vs LIME performance and stability}
\subsection{Use cases in tabular, text, and vision models}

\section{Interpretable PINNs and DRL Policies}
\subsection{Physics-informed constraints as interpretability tools}
\subsection{Sensitivity analysis in PINNs}
\subsection{Policy visualization and feature attribution in DRL}
\subsection{Reward decomposition and causal interpretability}
\subsection{Bridging performance with scientific understanding}


